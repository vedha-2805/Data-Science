{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863ae049-eb9a-4208-9a74-b8192c65c321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Transport Demand Prediction\n",
      "=================================\n",
      "This version avoids plotting errors and focuses on core analysis.\n",
      "\n",
      "To run:\n",
      "predictor = SimpleTransportPredictor('train_revised.csv')\n",
      "results = predictor.run_complete_analysis()\n"
     ]
    }
   ],
   "source": [
    "# Simple Transport Demand Prediction - Error-Free Version\n",
    "# This version focuses on analysis and modeling without complex plotting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SimpleTransportPredictor:\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"Initialize the predictor with data path\"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.raw_data = None\n",
    "        self.processed_data = None\n",
    "        self.models = {}\n",
    "        self.best_model = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and display basic information about the data\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"TRANSPORT DEMAND PREDICTION PROJECT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load data\n",
    "        self.raw_data = pd.read_csv(self.data_path)\n",
    "        print(f\"\\nüìä Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {self.raw_data.shape}\")\n",
    "        print(f\"Columns: {list(self.raw_data.columns)}\")\n",
    "        print(f\"\\nFirst 5 rows:\")\n",
    "        print(self.raw_data.head())\n",
    "        \n",
    "        return self.raw_data\n",
    "    \n",
    "    def create_target_variable(self):\n",
    "        \"\"\"Aggregate data to create target variable (seats sold per ride)\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"CREATING TARGET VARIABLE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Create unique ride identifier\n",
    "        self.raw_data['ride_identifier'] = (\n",
    "            self.raw_data['ride_id'].astype(str) + '_' + \n",
    "            self.raw_data['travel_date'].astype(str) + '_' + \n",
    "            self.raw_data['travel_time'].astype(str) + '_' + \n",
    "            self.raw_data['travel_from'].astype(str)\n",
    "        )\n",
    "        \n",
    "        # Aggregate to get seats sold per ride\n",
    "        aggregated = self.raw_data.groupby('ride_identifier').agg({\n",
    "            'ride_id': 'first',\n",
    "            'travel_date': 'first',\n",
    "            'travel_time': 'first',\n",
    "            'travel_from': 'first',\n",
    "            'travel_to': 'first',\n",
    "            'car_type': 'first',\n",
    "            'max_capacity': 'first',\n",
    "            'payment_method': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Mpesa',\n",
    "            'seat_number': 'count'  # This gives us seats sold\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Rename seat_number count to seats_sold (our target variable)\n",
    "        aggregated.rename(columns={'seat_number': 'seats_sold'}, inplace=True)\n",
    "        \n",
    "        # Calculate occupancy rate\n",
    "        aggregated['occupancy_rate'] = (aggregated['seats_sold'] / aggregated['max_capacity']) * 100\n",
    "        \n",
    "        self.processed_data = aggregated\n",
    "        \n",
    "        print(f\"‚úÖ Aggregated dataset created with {len(aggregated)} unique rides\")\n",
    "        print(f\"Target variable: seats_sold (range: {aggregated['seats_sold'].min()} - {aggregated['seats_sold'].max()})\")\n",
    "        print(f\"Average occupancy rate: {aggregated['occupancy_rate'].mean():.2f}%\")\n",
    "        \n",
    "        return self.processed_data\n",
    "    \n",
    "    def feature_engineering(self):\n",
    "        \"\"\"Create features for machine learning\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"FEATURE ENGINEERING\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        df = self.processed_data.copy()\n",
    "        \n",
    "        # Extract hour from travel_time\n",
    "        try:\n",
    "            df['travel_hour'] = df['travel_time'].astype(str).str.extract('(\\d+)').astype(float)\n",
    "            df['travel_hour'].fillna(7, inplace=True)  # Default to 7 AM\n",
    "        except:\n",
    "            df['travel_hour'] = 7\n",
    "        \n",
    "        # Create simple time categories\n",
    "        df['is_morning'] = (df['travel_hour'] < 12).astype(int)\n",
    "        df['is_bus'] = (df['car_type'] == 'Bus').astype(int)\n",
    "        df['is_mpesa'] = (df['payment_method'] == 'Mpesa').astype(int)\n",
    "        \n",
    "        # Route popularity (frequency of routes)\n",
    "        route_counts = df['travel_from'].value_counts()\n",
    "        df['route_popularity'] = df['travel_from'].map(route_counts)\n",
    "        \n",
    "        print(\"‚úÖ Features created:\")\n",
    "        print(\"   - travel_hour: Hour of departure\")\n",
    "        print(\"   - is_morning: 1 if departure before noon, 0 otherwise\")\n",
    "        print(\"   - is_bus: 1 if Bus, 0 if shuttle\")\n",
    "        print(\"   - is_mpesa: 1 if Mpesa payment, 0 if Cash\")\n",
    "        print(\"   - route_popularity: Frequency of the route\")\n",
    "        \n",
    "        self.processed_data = df\n",
    "        return df\n",
    "    \n",
    "    def analyze_data(self):\n",
    "        \"\"\"Perform basic data analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"DATA ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        df = self.processed_data\n",
    "        \n",
    "        print(\"üìä BASIC STATISTICS:\")\n",
    "        print(f\"   Total unique rides: {len(df)}\")\n",
    "        print(f\"   Average seats sold: {df['seats_sold'].mean():.2f}\")\n",
    "        print(f\"   Average occupancy rate: {df['occupancy_rate'].mean():.2f}%\")\n",
    "        print(f\"   Seats sold range: {df['seats_sold'].min()} - {df['seats_sold'].max()}\")\n",
    "        \n",
    "        print(\"\\nüõ£Ô∏è TOP 5 ROUTES BY AVERAGE SEATS SOLD:\")\n",
    "        route_performance = df.groupby('travel_from')['seats_sold'].mean().sort_values(ascending=False)\n",
    "        for i, (route, avg_seats) in enumerate(route_performance.head().items(), 1):\n",
    "            print(f\"   {i}. {route}: {avg_seats:.2f} seats\")\n",
    "        \n",
    "        print(\"\\nüöå VEHICLE TYPE PERFORMANCE:\")\n",
    "        vehicle_performance = df.groupby('car_type').agg({\n",
    "            'seats_sold': ['count', 'mean'],\n",
    "            'occupancy_rate': 'mean'\n",
    "        }).round(2)\n",
    "        print(vehicle_performance)\n",
    "        \n",
    "        print(\"\\nüí≥ PAYMENT METHOD ANALYSIS:\")\n",
    "        payment_performance = df.groupby('payment_method').agg({\n",
    "            'seats_sold': ['count', 'mean'],\n",
    "            'occupancy_rate': 'mean'\n",
    "        }).round(2)\n",
    "        print(payment_performance)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_features_for_modeling(self):\n",
    "        \"\"\"Prepare features for machine learning models\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PREPARING FEATURES FOR MODELING\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        df = self.processed_data.copy()\n",
    "        \n",
    "        # Select numerical features\n",
    "        numerical_features = ['max_capacity', 'travel_hour', 'route_popularity', \n",
    "                             'is_morning', 'is_bus', 'is_mpesa']\n",
    "        \n",
    "        # Select categorical features for encoding\n",
    "        categorical_features = ['travel_from']\n",
    "        \n",
    "        # Create feature matrix\n",
    "        X_numerical = df[numerical_features].fillna(0)\n",
    "        \n",
    "        # One-hot encode categorical variables\n",
    "        if len(categorical_features) > 0:\n",
    "            encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "            X_categorical = encoder.fit_transform(df[categorical_features])\n",
    "            \n",
    "            # Combine numerical and categorical features\n",
    "            X = np.hstack([X_numerical.values, X_categorical])\n",
    "            feature_names = numerical_features + list(encoder.get_feature_names_out(categorical_features))\n",
    "        else:\n",
    "            X = X_numerical.values\n",
    "            feature_names = numerical_features\n",
    "        \n",
    "        # Target variable\n",
    "        y = df['seats_sold'].values\n",
    "        \n",
    "        print(f\"‚úÖ Feature matrix created: {X.shape}\")\n",
    "        print(f\"‚úÖ Target variable: {y.shape}\")\n",
    "        print(f\"‚úÖ Features used: {feature_names}\")\n",
    "        \n",
    "        return X, y, feature_names\n",
    "    \n",
    "    def train_models(self, X, y):\n",
    "        \"\"\"Train multiple regression models\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING MACHINE LEARNING MODELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Define models\n",
    "        models = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Ridge Regression': Ridge(alpha=1.0),\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        print(\"Training models...\")\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\nüîÑ Training {name}...\")\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            # Cross-validation\n",
    "            try:\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "                cv_mean = cv_scores.mean()\n",
    "                cv_std = cv_scores.std()\n",
    "            except:\n",
    "                cv_mean = r2\n",
    "                cv_std = 0\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'mae': mae,\n",
    "                'mse': mse,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'cv_mean': cv_mean,\n",
    "                'cv_std': cv_std,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"   MAE: {mae:.3f}\")\n",
    "            print(f\"   RMSE: {rmse:.3f}\")\n",
    "            print(f\"   R¬≤: {r2:.3f}\")\n",
    "            print(f\"   CV Score: {cv_mean:.3f} ¬± {cv_std:.3f}\")\n",
    "        \n",
    "        self.models = results\n",
    "        self.X_test, self.y_test = X_test, y_test\n",
    "        \n",
    "        # Find best model\n",
    "        best_model_name = max(results.keys(), key=lambda k: results[k]['r2'])\n",
    "        self.best_model = results[best_model_name]['model']\n",
    "        self.best_model_name = best_model_name\n",
    "        \n",
    "        print(f\"\\nüèÜ Best model: {best_model_name} (R¬≤ = {results[best_model_name]['r2']:.3f})\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate and compare models\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"MODEL EVALUATION & COMPARISON\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Create comparison dataframe\n",
    "        comparison_data = []\n",
    "        for model_name, metrics in self.models.items():\n",
    "            comparison_data.append({\n",
    "                'Model': model_name,\n",
    "                'MAE': f\"{metrics['mae']:.3f}\",\n",
    "                'RMSE': f\"{metrics['rmse']:.3f}\",\n",
    "                'R¬≤': f\"{metrics['r2']:.3f}\",\n",
    "                'CV Score': f\"{metrics['cv_mean']:.3f} ¬± {metrics['cv_std']:.3f}\"\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        print(\"\\nüìä MODEL COMPARISON:\")\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Feature importance for tree-based models\n",
    "        if hasattr(self.best_model, 'feature_importances_'):\n",
    "            print(f\"\\nüéØ FEATURE IMPORTANCE ({self.best_model_name}):\")\n",
    "            feature_names = ['max_capacity', 'travel_hour', 'route_popularity', \n",
    "                           'is_morning', 'is_bus', 'is_mpesa'] + [f'route_{i}' for i in range(len(self.best_model.feature_importances_) - 6)]\n",
    "            \n",
    "            importances = self.best_model.feature_importances_\n",
    "            feature_importance = list(zip(feature_names[:len(importances)], importances))\n",
    "            feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for feature, importance in feature_importance[:10]:  # Top 10 features\n",
    "                print(f\"   {feature}: {importance:.4f}\")\n",
    "        \n",
    "        return comparison_df\n",
    "    \n",
    "    def generate_insights(self):\n",
    "        \"\"\"Generate business insights and recommendations\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"BUSINESS INSIGHTS & RECOMMENDATIONS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        df = self.processed_data\n",
    "        \n",
    "        # Key metrics\n",
    "        avg_occupancy = df['occupancy_rate'].mean()\n",
    "        high_demand_routes = df.groupby('travel_from')['seats_sold'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        print(\"üìä KEY BUSINESS METRICS:\")\n",
    "        print(f\"   Average occupancy rate: {avg_occupancy:.1f}%\")\n",
    "        print(f\"   Total rides analyzed: {len(df):,}\")\n",
    "        print(f\"   Average seats sold per ride: {df['seats_sold'].mean():.1f}\")\n",
    "        \n",
    "        print(\"\\nüéØ STRATEGIC RECOMMENDATIONS:\")\n",
    "        \n",
    "        print(\"\\n1. ROUTE OPTIMIZATION:\")\n",
    "        print(f\"   ‚Ä¢ Top performing route: {high_demand_routes.index[0]} ({high_demand_routes.iloc[0]:.1f} seats avg)\")\n",
    "        print(f\"   ‚Ä¢ Lowest performing route: {high_demand_routes.index[-1]} ({high_demand_routes.iloc[-1]:.1f} seats avg)\")\n",
    "        \n",
    "        if high_demand_routes.iloc[0] / high_demand_routes.iloc[-1] > 2:\n",
    "            print(\"   ‚Ä¢ Consider increasing frequency on top routes\")\n",
    "            print(\"   ‚Ä¢ Review scheduling for underperforming routes\")\n",
    "        \n",
    "        print(\"\\n2. CAPACITY MANAGEMENT:\")\n",
    "        underutilized = df[df['occupancy_rate'] < 30]\n",
    "        if len(underutilized) > len(df) * 0.2:\n",
    "            print(f\"   ‚Ä¢ {len(underutilized)} rides ({len(underutilized)/len(df)*100:.1f}%) are underutilized\")\n",
    "            print(\"   ‚Ä¢ Consider using smaller vehicles for low-demand routes\")\n",
    "        \n",
    "        print(\"\\n3. REVENUE OPTIMIZATION:\")\n",
    "        print(\"   ‚Ä¢ Implement dynamic pricing based on demand patterns\")\n",
    "        print(\"   ‚Ä¢ Offer early bird discounts for off-peak hours\")\n",
    "        print(\"   ‚Ä¢ Create loyalty programs for frequent routes\")\n",
    "        \n",
    "        return {\n",
    "            'avg_occupancy': avg_occupancy,\n",
    "            'top_route': high_demand_routes.index[0],\n",
    "            'model_performance': self.models[self.best_model_name]['r2']\n",
    "        }\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "        print(\"üöÄ Starting Transport Demand Analysis...\")\n",
    "        \n",
    "        # 1. Load data\n",
    "        self.load_data()\n",
    "        \n",
    "        # 2. Create target variable\n",
    "        self.create_target_variable()\n",
    "        \n",
    "        # 3. Feature engineering\n",
    "        self.feature_engineering()\n",
    "        \n",
    "        # 4. Analyze data\n",
    "        self.analyze_data()\n",
    "        \n",
    "        # 5. Prepare features for modeling\n",
    "        X, y, feature_names = self.prepare_features_for_modeling()\n",
    "        \n",
    "        # 6. Train models\n",
    "        self.train_models(X, y)\n",
    "        \n",
    "        # 7. Evaluate models\n",
    "        self.evaluate_models()\n",
    "        \n",
    "        # 8. Generate insights\n",
    "        insights = self.generate_insights()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéâ ANALYSIS COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"‚úÖ Best Model: {self.best_model_name}\")\n",
    "        print(f\"‚úÖ Model Performance: R¬≤ = {self.models[self.best_model_name]['r2']:.3f}\")\n",
    "        print(f\"‚úÖ Business Impact: {insights['avg_occupancy']:.1f}% average occupancy\")\n",
    "        print(f\"‚úÖ Key Insight: {insights['top_route']} is the top performing route\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# USAGE EXAMPLE:\n",
    "# ================\n",
    "# predictor = SimpleTransportPredictor('train_revised.csv')\n",
    "# results = predictor.run_complete_analysis()\n",
    "# \n",
    "# # Access results\n",
    "# print(f\"Best model R¬≤: {predictor.models[predictor.best_model_name]['r2']:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Simple Transport Demand Prediction\")\n",
    "    print(\"=================================\")\n",
    "    print(\"This version avoids plotting errors and focuses on core analysis.\")\n",
    "    print()\n",
    "    print(\"To run:\")\n",
    "    print(\"predictor = SimpleTransportPredictor('train_revised.csv')\")\n",
    "    print(\"results = predictor.run_complete_analysis()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967c9744-ed10-403b-9c45-137ef655bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Transport Demand Analysis...\n",
      "============================================================\n",
      "TRANSPORT DEMAND PREDICTION PROJECT\n",
      "============================================================\n",
      "\n",
      "üìä Dataset loaded successfully!\n",
      "Shape: (51645, 10)\n",
      "Columns: ['ride_id', 'seat_number', 'payment_method', 'payment_receipt', 'travel_date', 'travel_time', 'travel_from', 'travel_to', 'car_type', 'max_capacity']\n",
      "\n",
      "First 5 rows:\n",
      "   ride_id seat_number payment_method payment_receipt travel_date travel_time  \\\n",
      "0     1442         15A          Mpesa      UZUEHCBUSO    17-10-17        7:15   \n",
      "1     5437         14A          Mpesa      TIHLBUSGTE    19-11-17        7:12   \n",
      "2     5710          8B          Mpesa      EQX8Q5G19O    26-11-17        7:05   \n",
      "3     5777         19A          Mpesa      SGP18CL0ME    27-11-17        7:10   \n",
      "4     5778         11A          Mpesa      BM97HFRGL9    27-11-17        7:12   \n",
      "\n",
      "  travel_from travel_to car_type  max_capacity  \n",
      "0      Migori   Nairobi      Bus            49  \n",
      "1      Migori   Nairobi      Bus            49  \n",
      "2      Keroka   Nairobi      Bus            49  \n",
      "3    Homa Bay   Nairobi      Bus            49  \n",
      "4      Migori   Nairobi      Bus            49  \n",
      "\n",
      "==================================================\n",
      "CREATING TARGET VARIABLE\n",
      "==================================================\n",
      "‚úÖ Aggregated dataset created with 6249 unique rides\n",
      "Target variable: seats_sold (range: 1 - 50)\n",
      "Average occupancy rate: 39.05%\n",
      "\n",
      "==================================================\n",
      "FEATURE ENGINEERING\n",
      "==================================================\n",
      "‚úÖ Features created:\n",
      "   - travel_hour: Hour of departure\n",
      "   - is_morning: 1 if departure before noon, 0 otherwise\n",
      "   - is_bus: 1 if Bus, 0 if shuttle\n",
      "   - is_mpesa: 1 if Mpesa payment, 0 if Cash\n",
      "   - route_popularity: Frequency of the route\n",
      "\n",
      "==================================================\n",
      "DATA ANALYSIS\n",
      "==================================================\n",
      "üìä BASIC STATISTICS:\n",
      "   Total unique rides: 6249\n",
      "   Average seats sold: 8.26\n",
      "   Average occupancy rate: 39.05%\n",
      "   Seats sold range: 1 - 50\n",
      "\n",
      "üõ£Ô∏è TOP 5 ROUTES BY AVERAGE SEATS SOLD:\n",
      "   1. Sirare: 23.29 seats\n",
      "   2. Migori: 18.20 seats\n",
      "   3. Mbita: 18.00 seats\n",
      "   4. Homa Bay: 17.71 seats\n",
      "   5. Kehancha: 11.10 seats\n",
      "\n",
      "üöå VEHICLE TYPE PERFORMANCE:\n",
      "         seats_sold        occupancy_rate\n",
      "              count   mean           mean\n",
      "car_type                                 \n",
      "Bus            3189  10.03          20.47\n",
      "shuttle        3060   6.42          58.41\n",
      "\n",
      "üí≥ PAYMENT METHOD ANALYSIS:\n",
      "               seats_sold       occupancy_rate\n",
      "                    count  mean           mean\n",
      "payment_method                                \n",
      "Cash                   33  2.58          20.85\n",
      "Mpesa                6216  8.29          39.14\n",
      "\n",
      "==================================================\n",
      "PREPARING FEATURES FOR MODELING\n",
      "==================================================\n",
      "‚úÖ Feature matrix created: (6249, 22)\n",
      "‚úÖ Target variable: (6249,)\n",
      "‚úÖ Features used: ['max_capacity', 'travel_hour', 'route_popularity', 'is_morning', 'is_bus', 'is_mpesa', 'travel_from_Homa Bay', 'travel_from_Kehancha', 'travel_from_Kendu Bay', 'travel_from_Keroka', 'travel_from_Keumbu', 'travel_from_Kijauri', 'travel_from_Kisii', 'travel_from_Mbita', 'travel_from_Migori', 'travel_from_Ndhiwa', 'travel_from_Nyachenge', 'travel_from_Oyugis', 'travel_from_Rodi', 'travel_from_Rongo', 'travel_from_Sirare', 'travel_from_Sori']\n",
      "\n",
      "==================================================\n",
      "TRAINING MACHINE LEARNING MODELS\n",
      "==================================================\n",
      "Training models...\n",
      "\n",
      "üîÑ Training Linear Regression...\n",
      "   MAE: 4.731\n",
      "   RMSE: 6.825\n",
      "   R¬≤: 0.352\n",
      "   CV Score: 0.372 ¬± 0.030\n",
      "\n",
      "üîÑ Training Ridge Regression...\n",
      "   MAE: 4.731\n",
      "   RMSE: 6.822\n",
      "   R¬≤: 0.352\n",
      "   CV Score: 0.372 ¬± 0.029\n",
      "\n",
      "üîÑ Training Random Forest...\n",
      "   MAE: 4.359\n",
      "   RMSE: 6.460\n",
      "   R¬≤: 0.419\n",
      "   CV Score: 0.440 ¬± 0.022\n",
      "\n",
      "üîÑ Training Gradient Boosting...\n",
      "   MAE: 4.426\n",
      "   RMSE: 6.472\n",
      "   R¬≤: 0.417\n",
      "   CV Score: 0.436 ¬± 0.020\n",
      "\n",
      "üèÜ Best model: Random Forest (R¬≤ = 0.419)\n",
      "\n",
      "==================================================\n",
      "MODEL EVALUATION & COMPARISON\n",
      "==================================================\n",
      "\n",
      "üìä MODEL COMPARISON:\n",
      "            Model   MAE  RMSE    R¬≤      CV Score\n",
      "Linear Regression 4.731 6.825 0.352 0.372 ¬± 0.030\n",
      " Ridge Regression 4.731 6.822 0.352 0.372 ¬± 0.029\n",
      "    Random Forest 4.359 6.460 0.419 0.440 ¬± 0.022\n",
      "Gradient Boosting 4.426 6.472 0.417 0.436 ¬± 0.020\n",
      "\n",
      "üéØ FEATURE IMPORTANCE (Random Forest):\n",
      "   route_popularity: 0.2895\n",
      "   route_14: 0.2167\n",
      "   travel_hour: 0.1333\n",
      "   route_8: 0.0991\n",
      "   route_0: 0.0837\n",
      "   is_morning: 0.0657\n",
      "   route_5: 0.0399\n",
      "   route_3: 0.0195\n",
      "   route_10: 0.0156\n",
      "   route_13: 0.0107\n",
      "\n",
      "==================================================\n",
      "BUSINESS INSIGHTS & RECOMMENDATIONS\n",
      "==================================================\n",
      "üìä KEY BUSINESS METRICS:\n",
      "   Average occupancy rate: 39.0%\n",
      "   Total rides analyzed: 6,249\n",
      "   Average seats sold per ride: 8.3\n",
      "\n",
      "üéØ STRATEGIC RECOMMENDATIONS:\n",
      "\n",
      "1. ROUTE OPTIMIZATION:\n",
      "   ‚Ä¢ Top performing route: Sirare (23.3 seats avg)\n",
      "   ‚Ä¢ Lowest performing route: Kendu Bay (1.0 seats avg)\n",
      "   ‚Ä¢ Consider increasing frequency on top routes\n",
      "   ‚Ä¢ Review scheduling for underperforming routes\n",
      "\n",
      "2. CAPACITY MANAGEMENT:\n",
      "   ‚Ä¢ 3461 rides (55.4%) are underutilized\n",
      "   ‚Ä¢ Consider using smaller vehicles for low-demand routes\n",
      "\n",
      "3. REVENUE OPTIMIZATION:\n",
      "   ‚Ä¢ Implement dynamic pricing based on demand patterns\n",
      "   ‚Ä¢ Offer early bird discounts for off-peak hours\n",
      "   ‚Ä¢ Create loyalty programs for frequent routes\n",
      "\n",
      "============================================================\n",
      "üéâ ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "‚úÖ Best Model: Random Forest\n",
      "‚úÖ Model Performance: R¬≤ = 0.419\n",
      "‚úÖ Business Impact: 39.0% average occupancy\n",
      "‚úÖ Key Insight: Sirare is the top performing route\n",
      "Best model R¬≤: 0.419\n"
     ]
    }
   ],
   "source": [
    "# Use the error-free simple version\n",
    "predictor = SimpleTransportPredictor('train_revised.csv')\n",
    "results = predictor.run_complete_analysis()\n",
    "\n",
    "# Access results\n",
    "print(f\"Best model R¬≤: {predictor.models[predictor.best_model_name]['r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ccacc3-c9c4-47d3-adad-1ee6d29ba812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
